# Ответ GPT
Представление графа в числовом виде — это важная задача в области графовой аналитики и машинного обучения. Эмбеддинг графа позволяет преобразовать узлы и структуры графов в векторные представления, что упрощает анализ и сравнение графов.

### Подходы к эмбеддингу графов

**1. Эмбеддинг на основе узлов:**
- **Node2Vec:** Этот алгоритм генерирует векторы для узлов, используя случайные блуждания по графу. Узлы, которые находятся близко друг к другу в графе, будут иметь схожие векторы в пространстве.
- **DeepWalk:** Это аналогичный подход, использующий случайные блуждания и задающий цель максимизации вероятности совместного появления узлов. В результате, вы получаете векторные представления для каждого узла.
**2. Эмбеддинг всего графа:**
- **GraphSAGE (Graph Sample and Aggregation):** Этот метод использует информацию о соседних узлах для генерации представлений графа. Он может агрегировать информацию о сообществах узлов, что делает его подходящим для больших графов.
- **Graph Neural Networks (GNN):** Эти сети используют архитектуры нейронных сетей для обработки графов. Они могут быть эффективны для задач классификации узлов, графов или предсказания связей.
**3. Методы на основе матриц:**
- **Adjacency Matrix:** Исходя из вашей структуры графа, вы можете создать матрицу смежности, где строки и столбцы соответствуют узлам, а значения — весам рёбер. Это может быть использовано для последующей обработки.
- **Laplacian Matrix:** Лаплассовая матрица графа может быть использована для выявления структурных свойств графа.
### Применение на практике

Для вашего графа цитирования вы можете:
- Начать с генерации эмбеддингов для каждого узла с помощью Node2Vec или DeepWalk.
- Оценить важность узлов через PageRank.
- Сохранить векторы узлов и построить динамическую матрицу, где строки соответствуют различным графам и столбцы — узлам, чтобы машина могла сравнивать графы на основе значимости узлов и их взаимосвязей.
Таким образом, вы сможете получить обширное представление о структуре графов и их взаимосвязях, что упростит дальнейший анализ и построение моделей.

# Мои мысли
Гпт предложил хорошую идею в 3 пункте в абзаце "Применение на практике".
А развить эту идею можно так:
1) Пройтись по графу page rank'ом. Тем самым отсортируем все узлы по их важности
2) Взять эмбеддинги top K узлов по важности. И объединить эти K эмбеддингов в ряд.
3) Проделать шаги 1-2 для графов на других временных промежутках, а результаты объединить в матрицу
В результате, у нас будет **матрица размера** $(t, K, n)$, где:
- $t$ - это количество графов (промежутков времени, на которые разбили выбранный временной отрезок) 
- K - количество лучших вершин, отбираемых из графа
- n - длина эмбеддинга

Проблема в том, что в трансформер хорошо бы подавать двумерную матрицу (как временной ряд, где в каждой точке эмбеддинг). А сейчас у нас получается, что в каждой точке временного ряда не эмбеддинг, а K эмбеддингов.
