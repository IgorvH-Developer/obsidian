
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

## Инвертированный поиск
### Блочное хранение.
Используется потому что чтение
Потому что проще считать 

**Индекс**.
Индекс - сегменты - поля - блоки
$s_1, ..., s_k$
$s_1 = \{ d \in D\} s_i \cap s_j = 0$

Блоки: 
$terms \space dict \to \{ parts \space of \space docs\}$ 
Здесь (вверху) хранятся ещё и поинтеры 
$s_d =  \{ block_{0...n-1} \to blocks{n_2N} \to ...\}$ - тут реализованы скип листы
Наши блоки разбиты на слои, мы один ко одному записываем сколько term встретился в документе.

Без term frequncy не будет работать ранжированный индекс

**Прямой индекс**.
posting-list $doc_i d_i(dields) что-то...ещё$

**Reuters**.
Это коллекция документов. Тут примерно 900к документов. Примерно 100к уник слов.

*Для чего мы хотим сжимать индекс*? Чтобы лучше работать с шиной данный.

### Словарь
- Без сжатия.
$[term_1, term_2, ..., term_m]$

Пример:
[7 automat|1e|3ion|7ization]
То есть префиксное дерево нужно, чтобы искать термины начинающиеся с такого-то префикса. В примере выше говорится, что у нас есть узел automat (есть 7 терминов начинающиеся), дальше есть подузлы: "e"(1 термин), "ion"(3 термина), "ization"(7 терминов таких).

Ещё у каждого узла, то есть части термина хранится поинтер на кишку (на постинг листы). То есть мы реализуем структуру, в которой листу указывают ссылки на постинг-листы.

Структура префиксного дерева по английски - trie. Схожие термины b-trie, b+trie.

#### Как сжимать постинг листы
Постинг лист - это по сути массив чисел (идентификаторы документов). Постинг листы **упорядочены** (надо это проверить, скоее всего нет).

**Вся идея всех сжатий заключается, в том, что данные не меняются**. То есть не меняем те структуры, которые уже были. Если приходят, то добавляем новый блок и так далее.

На вход список индексов. Как хранить не int32, а меньше? То есть как эффективнее хранить массив этих индексов.
**Вариант 1**:
Давайте хранить столько бит:
$max_i(log_2(id_{doc}))$ (и округляем вниз)
**Вариант 2. Delta-encoding**:
То есть уменьшаем кол-во бит на каждое число.
Есть: |id_1|id_2|id_3|
Давайте это хранить как: |id_1|id_2-id_1|id_3-id_2|
**Вариант 3. pForDelta**:
Для варианта выше мы берём напр 80% дельт. То есть у нас могут быть исключения, которые могут быть большими и выдавать большое число в варианте 1, то есть заставляют нас хранить больше бит. Чтобы этого избежать мы кодируем 80% дельта, а если мы сохраняем 0 (после применения варианта 2 мы ноль не храним), то это означает, что у нас есть эти самые выбросы (исключения).
Получаем:
|delta encoding|список исключений|
t max                  

#### byte var
Его мы используем поверх delta кодирования, если хотим сэкономить на битовых операция.
После применения всяких сокращений у нас постинг лист из массива байтов превращается в массив бит, а это может очень сильно замедлить разкодирование.

Допустим:
1                     2     1    3
int32(про 1)

В битовой записи байтов мы используем управляющий бит (первый в байте т.е. самый левый бит из 8 битов для байтов). Получается у 7 эффективный битов и один управляющий. В управляющем бите 1 значит, что запись нашего числа продолжается и в следующем байте.

#### $\gamma$ - encoding

delta  1_3 = 1_101 (по цифернно перевели в двоичный формат)
Давайте цифры кодировать как:
1: 10
2: 110
3:1110
n: n единичек и 0

gamma(delte) = $log_2(delte) + log_2(delte) = 2log_2D + 2$  где первый  log округляем вниз, а второй вверх


####
Основная гипотеза, что у нас в кишках нет перевеса по doc id. То есть распределение примерно равномерное.
При проходе по постингу листу doc id всегда возрастают.

И можно делта кодировать id документа так:
$docId_i = a + b*i + delta$          (округляем вверх)
, i - позиция в массиве (в постинг листе).
То есть кодируем id документа как отклонение от какой-то прямой, которая при продвижении по постингу листу идёт примерно по doc id. 
