### Напоминание.
Мы говорили, что оценки релевантности как правило оценки $R =\{ 0,1,2,3,4,5\}$
И есть люди, которые получает на вход $\{D,Q\}$ и выдают для них оценку $\{D,Q,R\}$
И мы считаем, что у нас есть асессоры (которым мы всегда верим) и есть толпа.

Мы проделываем это n раз для асессоров и толпы и получаем $\{D,Q,R\}$ n раз. И вопрос **как агрегировать эти оценки**?
Есть варианты:
1) **Оценка по большинству**. (для бедных)
   Пример [0,1,1,0,1], тут выбираем 1.
   Но проблема в том, что 
   - это работает только для бинарных оценок
   - не учитываем асессора 
2) **Экзамен. Honey pot.** (Для богатых)
   Мы к оценкам $\{D,Q\}$ добавляем экзамен, то есть пары запрос/документ, для которых уже есть оценка (Для богатых)
3) Дэвид-Скин.
   k - номер асессора
   i - номер задачи
   l - оценка
   - одно задание, один асессор, n-раз ($n_{il}^n$)
   - оценки независимы
   - $\Pi_{il}^k$  - не зависят от запроса. Это confusion matrix. i - истинная оценка, l - оценка асессора.
   - $T_{ij} = 1 -$ если i-ая задача имеет rel=j, $0 -$ в других случаях 
   - 
